{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 70\n",
      "Iteration 71\n",
      "Iteration 72\n",
      "Iteration 73\n",
      "Iteration 74\n",
      "Iteration 75\n",
      "Iteration 76\n",
      "Iteration 77\n",
      "Iteration 78\n",
      "Iteration 79\n",
      "Iteration 80\n",
      "Iteration 81\n",
      "Iteration 82\n",
      "Iteration 83\n",
      "Iteration 84\n",
      "Iteration 85\n",
      "Iteration 86\n",
      "Iteration 87\n",
      "Iteration 88\n",
      "Iteration 89\n",
      "Iteration 90\n",
      "Iteration 91\n",
      "Iteration 92\n",
      "Iteration 93\n",
      "Iteration 94\n",
      "Iteration 95\n",
      "Iteration 96\n",
      "Iteration 97\n",
      "Iteration 98\n",
      "Iteration 99\n",
      "Iteration 100\n",
      "Iteration 101\n",
      "Iteration 102\n",
      "Iteration 103\n",
      "Iteration 104\n",
      "Iteration 105\n",
      "Iteration 106\n",
      "Iteration 107\n",
      "Iteration 108\n",
      "Iteration 109\n",
      "Iteration 110\n",
      "Iteration 111\n",
      "Iteration 112\n",
      "Iteration 113\n",
      "Iteration 114\n",
      "Iteration 115\n",
      "Iteration 116\n",
      "Iteration 117\n",
      "Iteration 118\n",
      "Iteration 119\n",
      "Iteration 120\n",
      "Iteration 121\n",
      "Iteration 122\n",
      "Iteration 123\n",
      "Iteration 124\n",
      "Iteration 125\n",
      "Iteration 126\n",
      "Iteration 127\n",
      "Iteration 128\n",
      "Iteration 129\n",
      "Iteration 130\n",
      "Iteration 131\n",
      "Iteration 132\n",
      "Iteration 133\n",
      "Iteration 134\n",
      "Iteration 135\n",
      "Iteration 136\n",
      "Iteration 137\n",
      "Iteration 138\n",
      "Iteration 139\n",
      "Iteration 140\n",
      "Iteration 141\n",
      "Iteration 142\n",
      "Iteration 143\n",
      "Iteration 144\n",
      "Iteration 145\n",
      "Iteration 146\n",
      "Iteration 147\n",
      "Iteration 148\n",
      "Iteration 149\n",
      "Iteration 150\n",
      "Iteration 151\n",
      "Iteration 152\n",
      "Iteration 153\n",
      "Iteration 154\n",
      "Iteration 155\n",
      "Iteration 156\n",
      "Iteration 157\n",
      "Iteration 158\n",
      "Iteration 159\n",
      "Iteration 160\n",
      "Iteration 161\n",
      "Iteration 162\n",
      "Iteration 163\n",
      "Iteration 164\n",
      "Iteration 165\n",
      "Iteration 166\n",
      "Iteration 167\n",
      "Iteration 168\n",
      "Iteration 169\n",
      "Iteration 170\n",
      "Iteration 171\n",
      "Iteration 172\n",
      "Iteration 173\n",
      "Iteration 174\n",
      "Iteration 175\n",
      "Iteration 176\n",
      "Iteration 177\n",
      "Iteration 178\n",
      "Iteration 179\n",
      "Iteration 180\n",
      "Iteration 181\n",
      "Iteration 182\n",
      "Iteration 183\n",
      "Iteration 184\n",
      "Iteration 185\n",
      "Iteration 186\n",
      "Iteration 187\n",
      "Iteration 188\n",
      "Iteration 189\n",
      "Iteration 190\n",
      "Iteration 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from modules import *\n",
    "from utils import *\n",
    "\n",
    "########## have to import a EEG snippet from somewhere\n",
    "#img_path = '/Users/fchollet/Downloads/creative_commons_elephant.jpg'\n",
    "df = pd.read_csv(\"E:/sleepEDFx/pat2cha3.csv\")\n",
    "EEG_sample = df.iloc[1002].values\n",
    "stage = EEG_sample[-2]\n",
    "EEG_sample = EEG_sample[:-2]\n",
    "EEG_sample = np.expand_dims(EEG_sample,axis=-1)\n",
    "EEG_sample = np.expand_dims(EEG_sample, axis=0)\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Model reconstruction from JSON file\n",
    "with open('E:/SleepWell/ASSC/models/allDataChannel1_2019-01-05 15-58-12.139755/model.json', 'r') as f:\n",
    "    model = model_from_json(f.read(), {'Scale': Scale})\n",
    "\n",
    "# Load weights into the new model\n",
    "model.load_weights('E:/SleepWell/ASSC/models/allDataChannel1_2019-01-05 15-58-12.139755/weights.0001-0.8122.hdf5')\n",
    "val= int(stage)-1\n",
    "\n",
    "\n",
    "############# GradCAM stffffff ###########################\n",
    "\n",
    "output = model.output[:,val]\n",
    "last_conv_layer = model.get_layer('conv1d_20') ##### have to change the name here\n",
    "\n",
    "\n",
    "grads = K.gradients(output, last_conv_layer.output)[0]\n",
    "pooled_grads = K.mean(grads, axis=(0, 1)) ### no idea what to do here\n",
    "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "pooled_grads_value, conv_layer_output_value = iterate([EEG_sample])\n",
    "for i in range(192):\n",
    "    print(\"Iteration %d\" % i)\n",
    "    conv_layer_output_value[ :, i] *= pooled_grads_value[i]\n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "\n",
    "\n",
    "\n",
    "# plt.matshow(heatmap)\n",
    "\n",
    "\n",
    "# img = cv2.imread(img_path)\n",
    "# heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "# heatmap = np.uint8(255 * heatmap)\n",
    "# heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "# superimposed_img = heatmap * 0.4 + img\n",
    "# #cv2.imwrite('/Users/fchollet/Downloads/elephant_cam.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan], dtype=float32)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "x = np.linspace(0, 3000, num=187)\n",
    "y = heatmap\n",
    "f1 = interp1d(x, y, kind='cubic')\n",
    "xnew = np.linspace(0, 3000, num=3000)\n",
    "ynew = f1(xnew)\n",
    "print(\"Stage %d\" % stage)\n",
    "plt.plot(xnew, ynew)\n",
    "plt.plot(EEG_sample[0,:,0]/np.std(EEG_sample[0,:,0])+1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'numpy' from 'C:\\\\Users\\\\User\\\\Anaconda3\\\\envs\\\\thesis\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py'>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<scipy.interpolate.interpolate.interp1d object at 0x000001563AAEB868>,\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = np.array(f1)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 3000, 64)     1088        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 3000, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "scale_1 (Scale)                 (None, 3000, 64)     128         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 3000, 64)     0           scale_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 3000, 64)     65536       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 3000, 64)     256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "scale_2 (Scale)                 (None, 3000, 64)     128         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 3000, 64)     0           scale_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 3000, 64)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 3000, 64)     65536       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 3000, 64)     0           conv1d_3[0][0]                   \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 3000, 64)     256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_3 (Scale)                 (None, 3000, 64)     128         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 3000, 64)     0           scale_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 3000, 64)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 3000, 64)     65536       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1500, 64)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1500, 64)     256         max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale_4 (Scale)                 (None, 1500, 64)     128         batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1500, 64)     0           scale_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1500, 64)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 3000, 64)     65536       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1500, 64)     65536       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1500, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1500, 64)     0           conv1d_5[0][0]                   \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1500, 64)     256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_5 (Scale)                 (None, 1500, 64)     128         batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1500, 64)     0           scale_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1500, 64)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1500, 64)     65536       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1500, 64)     256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "scale_6 (Scale)                 (None, 1500, 64)     128         batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1500, 64)     0           scale_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1500, 64)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1500, 64)     65536       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1500, 64)     0           conv1d_8[0][0]                   \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1500, 64)     256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_7 (Scale)                 (None, 1500, 64)     128         batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1500, 64)     0           scale_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1500, 64)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1500, 64)     65536       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 750, 64)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 750, 64)      256         max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale_8 (Scale)                 (None, 750, 64)      128         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 750, 64)      0           scale_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 750, 64)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1500, 128)    131072      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 750, 128)     131072      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 750, 128)     0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 750, 128)     0           conv1d_10[0][0]                  \n",
      "                                                                 max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 750, 128)     512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_9 (Scale)                 (None, 750, 128)     256         batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 750, 128)     0           scale_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 750, 128)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 750, 128)     262144      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 750, 128)     512         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "scale_10 (Scale)                (None, 750, 128)     256         batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 750, 128)     0           scale_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 750, 128)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 750, 128)     262144      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 750, 128)     0           conv1d_13[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 750, 128)     512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_11 (Scale)                (None, 750, 128)     256         batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 750, 128)     0           scale_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 750, 128)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 750, 128)     262144      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 375, 128)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 375, 128)     512         max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale_12 (Scale)                (None, 375, 128)     256         batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 375, 128)     0           scale_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 375, 128)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 750, 128)     262144      add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 375, 128)     262144      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 375, 128)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 375, 128)     0           conv1d_15[0][0]                  \n",
      "                                                                 max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 375, 128)     512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_13 (Scale)                (None, 375, 128)     256         batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 375, 128)     0           scale_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 375, 128)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 375, 128)     262144      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 375, 128)     512         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "scale_14 (Scale)                (None, 375, 128)     256         batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 375, 128)     0           scale_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 375, 128)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 375, 128)     262144      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 375, 128)     0           conv1d_18[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 375, 128)     512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_15 (Scale)                (None, 375, 128)     256         batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 375, 128)     0           scale_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 375, 128)     0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 375, 128)     262144      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 187, 128)     0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 187, 128)     512         max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale_16 (Scale)                (None, 187, 128)     256         batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 187, 128)     0           scale_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 187, 128)     0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 375, 192)     393216      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 187, 192)     393216      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 187, 192)     0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 187, 192)     0           conv1d_20[0][0]                  \n",
      "                                                                 max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 187, 192)     768         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_17 (Scale)                (None, 187, 192)     384         batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 187, 192)     0           scale_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 187, 192)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 187, 192)     589824      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 187, 192)     768         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "scale_18 (Scale)                (None, 187, 192)     384         batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 187, 192)     0           scale_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 187, 192)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 187, 192)     589824      dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 187, 192)     0           conv1d_23[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 187, 192)     768         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_19 (Scale)                (None, 187, 192)     384         batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 187, 192)     0           scale_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 187, 192)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 187, 192)     589824      dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 93, 192)      0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 93, 192)      768         max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale_20 (Scale)                (None, 93, 192)      384         batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 93, 192)      0           scale_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 93, 192)      0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 187, 192)     589824      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 93, 192)      589824      dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 93, 192)      0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 93, 192)      0           conv1d_25[0][0]                  \n",
      "                                                                 max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 93, 192)      768         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "scale_21 (Scale)                (None, 93, 192)      384         batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 93, 192)      0           scale_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 93, 192)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 93, 192)      589824      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 93, 192)      768         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "scale_22 (Scale)                (None, 93, 192)      384         batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 93, 192)      0           scale_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 93, 192)      0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 93, 192)      589824      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 93, 192)      0           conv1d_28[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 93, 192)      768         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "scale_23 (Scale)                (None, 93, 192)      384         batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 93, 192)      0           scale_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 93, 192)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 93, 192)      589824      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 46, 192)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 46, 192)      768         max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale_24 (Scale)                (None, 46, 192)      384         batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 46, 192)      0           scale_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 46, 192)      0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 93, 256)      786432      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 46, 256)      786432      dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 46, 256)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 46, 256)      0           conv1d_30[0][0]                  \n",
      "                                                                 max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 46, 256)      1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "scale_25 (Scale)                (None, 46, 256)      512         batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 46, 256)      0           scale_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 46, 256)      0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 46, 256)      1048576     dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 46, 256)      1024        conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "scale_26 (Scale)                (None, 46, 256)      512         batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 46, 256)      0           scale_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 46, 256)      0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 46, 256)      1048576     dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 46, 256)      0           conv1d_33[0][0]                  \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 46, 256)      1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "scale_27 (Scale)                (None, 46, 256)      512         batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 46, 256)      0           scale_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 46, 256)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 46, 256)      1048576     dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 23, 256)      0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 23, 256)      1024        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale_28 (Scale)                (None, 23, 256)      512         batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 23, 256)      0           scale_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 23, 256)      0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 46, 256)      1048576     add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 23, 256)      1048576     dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 23, 256)      0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 23, 256)      0           conv1d_35[0][0]                  \n",
      "                                                                 max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 23, 256)      1024        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "scale_29 (Scale)                (None, 23, 256)      512         batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 23, 256)      0           scale_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 23, 256)      0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 23, 256)      1048576     dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 23, 256)      1024        conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "scale_30 (Scale)                (None, 23, 256)      512         batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 23, 256)      0           scale_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 23, 256)      0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 23, 256)      1048576     dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 23, 256)      0           conv1d_38[0][0]                  \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 23, 256)      1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "scale_31 (Scale)                (None, 23, 256)      512         batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 23, 256)      0           scale_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 23, 256)      0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 23, 256)      1048576     dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 11, 256)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 11, 256)      1024        max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale_32 (Scale)                (None, 11, 256)      512         batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 11, 256)      0           scale_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 11, 256)      0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 23, 512)      2097152     add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 11, 512)      2097152     dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 11, 512)      0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 11, 512)      0           conv1d_40[0][0]                  \n",
      "                                                                 max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 11, 512)      2048        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "scale_33 (Scale)                (None, 11, 512)      1024        batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 11, 512)      0           scale_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5632)         0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7)            39431       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,618,695\n",
      "Trainable params: 22,607,431\n",
      "Non-trainable params: 11,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(Y, classes):\n",
    "    num_samples = len(Y)\n",
    "    n_classes = len(classes)\n",
    "    num_bin = np.bincount(Y[:, 0])\n",
    "    class_weights = {i: (num_samples / (n_classes * num_bin[i])) for i in range(6)}\n",
    "    return class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 30, 11, 15, 29, 8, 48, 24, 40, 54, 16, 37, 10, 39, 7, 18, 42, 57, 31]\n",
      "35\n",
      "21\n",
      "22\n",
      "43\n",
      "9\n",
      "56\n",
      "34\n",
      "58\n",
      "26\n",
      "6\n",
      "3\n",
      "55\n",
      "33\n",
      "2\n",
      "27\n",
      "13\n",
      "46\n",
      "45\n",
      "38\n",
      "47\n",
      "17\n",
      "5\n",
      "25\n",
      "32\n",
      "1\n",
      "52\n",
      "50\n",
      "12\n",
      "41\n",
      "51\n",
      "4\n",
      "19\n",
      "0\n",
      "23\n",
      "53\n",
      "49\n",
      "36\n",
      "20\n",
      "44\n",
      "60\n",
      "59\n",
      "28\n",
      "14\n",
      "30\n",
      "11\n",
      "15\n",
      "29\n",
      "8\n",
      "48\n",
      "24\n",
      "40\n",
      "54\n",
      "16\n",
      "37\n",
      "10\n",
      "39\n",
      "7\n",
      "18\n",
      "42\n",
      "57\n",
      "31\n",
      "Dataframe has been loaded\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-bceeee1d6654>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mdummytrainY\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdummytrainY\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#print(Counter(trainY))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtrainY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_classes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mvalY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalY\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_classes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mtrainX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#df2 = pd.read_csv('E:/SleepWell/ASSC-master/data/purifiedallDataChannel2.csv', header=None)\n",
    "#df2.rename({3000: 'hyp', 3001: 'epoch', 3002: 'patID'}, axis=\"columns\", inplace=True)\n",
    "from keras.utils import to_categorical, plot_model\n",
    "trainX, valX, trainY, valY, pat_train, pat_val = patientSplitter('randomizedIDs.csv', df2, 0.7)\n",
    "print(\"Dataframe has been loaded\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####               \n",
    "\n",
    "    ######                ,      ##############\n",
    "\n",
    "dummytrainY = trainY.astype(int)-1\n",
    "dummytrainY= dummytrainY\n",
    "#print(Counter(trainY))\n",
    "trainY = to_categorical(trainY-1, 7)\n",
    "valY = to_categorical(valY-1, 7)\n",
    "trainX = np.expand_dims(trainX,axis=-1)\n",
    "valX = np.expand_dims(valX, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patientSplitter(randomIDfile,df2,split_portion):\n",
    "    import pandas as pd\n",
    "\n",
    "    df1 = pd.read_csv(randomIDfile,header=None)\n",
    "    split_portion_numer=int(split_portion*61)\n",
    "\n",
    "    train_pat_list = [int(each) for each in df1.iloc[:split_portion_numer].values]\n",
    "    test_pat_list = [int(each) for each in df1.iloc[split_portion_numer:].values]\n",
    "    print(test_pat_list)\n",
    "    df3 = []\n",
    "    df4 = []\n",
    "    for pat_ID in train_pat_list:\n",
    "        df3.append(df2[df2.patID == pat_ID].values)\n",
    "        print(pat_ID)\n",
    "    for pat_ID in test_pat_list:\n",
    "        df4.append(df2[df2.patID == pat_ID].values)\n",
    "        print(pat_ID)\n",
    "    del df2\n",
    "    df3 = pd.np.vstack(df3)\n",
    "    df4 = pd.np.vstack(df4)\n",
    "    X_train = df3[:, :3000]\n",
    "    X_test= df4[:, :3000]\n",
    "    Y_train= df3[:,3000]\n",
    "    Y_test= df4[:,3000]\n",
    "    pat_train=df3[:, 3002:3003]\n",
    "    pat_test= df4[:, 3002:3003]\n",
    "\n",
    "    del pd\n",
    "    return X_train,X_test,Y_train,Y_test,pat_train,pat_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-415311aacff9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcompute_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummytrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummytrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-94bfe83e0b95>\u001b[0m in \u001b[0;36mcompute_weight\u001b[1;34m(Y, classes)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnum_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mclass_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_bin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "compute_weight(dummytrainY, np.unique(dummytrainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82843,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainY).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dummytrainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classweights': 'kjhaskdfj', 'kjhk': 'jhksadfjhaksjdfhak'}\n"
     ]
    }
   ],
   "source": [
    "a= {'classweights': \"kjhaskdfj\", 'kjhk': \"jhksadfjhaksjdfhak\"}\n",
    "# a.pop('classweights')\n",
    "print(a)\n",
    "params = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"E:/SleepWell/ASSC/logs/allDataChannel1_2019-01-07 12-23-06.911431/training.csv\", index_col=False)\n",
    "df1 = df1.sort_values('val_acc')\n",
    "a = df1.head(1)\n",
    "# print(a)\n",
    "# b = a.to_dict()\n",
    "# print(b)\n",
    "a = a.join(pd.DataFrame(params,index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>classweights</th>\n",
       "      <th>kjhk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.791014</td>\n",
       "      <td>0.576767</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.734471</td>\n",
       "      <td>0.888149</td>\n",
       "      <td>kjhaskdfj</td>\n",
       "      <td>jhksadfjhaksjdfhak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch       acc      loss        lr   val_acc  val_loss classweights  \\\n",
       "0      0  0.791014  0.576767  0.000691  0.734471  0.888149    kjhaskdfj   \n",
       "\n",
       "                 kjhk  \n",
       "0  jhksadfjhaksjdfhak  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_acc': {0: 0.7344706100500649}, 'lr': {0: 0.0006910841329954566}, 'epoch': {0: 0}, 'loss': {0: 0.5767672482317713}, 'val_loss': {0: 0.8881486440707747}, 'acc': {0: 0.7910143283099214}}\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   epoch       acc      loss        lr   val_acc  val_loss\n",
      "0      0  0.791014  0.576767  0.000691  0.734471  0.888149\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.791014</td>\n",
       "      <td>0.576767</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.734471</td>\n",
       "      <td>0.888149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch       acc      loss        lr   val_acc  val_loss\n",
       "0      0  0.791014  0.576767  0.000691  0.734471  0.888149"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:/sleepEDFx/pat2cha3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>34.984</th>\n",
       "      <th>39.325</th>\n",
       "      <th>52.347</th>\n",
       "      <th>52.829</th>\n",
       "      <th>48.488</th>\n",
       "      <th>31.126</th>\n",
       "      <th>26.785</th>\n",
       "      <th>21.48</th>\n",
       "      <th>23.409</th>\n",
       "      <th>11.352</th>\n",
       "      <th>...</th>\n",
       "      <th>-34.949.11</th>\n",
       "      <th>-34.949.12</th>\n",
       "      <th>-16.139.13</th>\n",
       "      <th>-44.112.11</th>\n",
       "      <th>-34.949.13</th>\n",
       "      <th>-50.382.4</th>\n",
       "      <th>-53.758.7</th>\n",
       "      <th>-119.83.2</th>\n",
       "      <th>9</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [34.984, 39.325, 52.347, 52.829, 48.488, 31.126, 26.785, 21.48, 23.409, 11.352, 46.559, 38.36, 16.657, 33.055, 28.232, 31.126.1, 31.126.2, 24.374, 5.0818, 33.537, -0.70574, 2.6703, 26.785.1, 1.2234, 6.5287, -6.011, -2.1526, -17.104, 4.1172, 2.188, -9.3871, -23.374, 20.515, -17.586, -32.537, 4.5995, 5.5641, -6.011.1, -14.692, -4.5641, -23.856, -11.316, -0.70574.1, -23.856.1, -17.104.1, -11.799, -31.09, -17.586.1, -28.197, -33.984, -25.303, -19.998, -32.055, -12.281, -6.9756, -21.444, -14.692.1, -24.338, -22.409, -38.325, -23.374.1, -19.033, -17.104.2, -24.338.1, -22.409.1, -26.75, -27.232, -37.842, -22.409.2, -15.175, -23.374.2, -39.289, -6.011.2, -31.573, -26.267, -33.02, -24.338.2, -42.665, -28.679, -38.325.1, -41.701, -39.772, -22.891, -19.998.1, -26.75.1, -12.763, -32.537.1, -32.537.2, -39.772.1, -41.219, -16.139, -20.962, -35.431, -24.821, -1.6703, -35.431.1, -53.276, -32.055.1, -18.068, -12.763.1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 3002 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
